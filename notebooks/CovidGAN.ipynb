{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"opencovidgan.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["from __future__ import print_function, division\n","\n","from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Multiply, concatenate, Conv2DTranspose\n","from tensorflow.keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import UpSampling2D, Conv2D\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.activations import relu, tanh, linear\n","from tensorflow import keras\n","from tensorflow.keras.utils import Progbar\n","import tensorflow as tf\n","\n","from collections import defaultdict\n","import pickle as pickle\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","\n","import numpy as np\n","import os\n","\n","np.random.seed(1337)"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-03T08:42:14.788099Z","iopub.execute_input":"2022-05-03T08:42:14.788485Z","iopub.status.idle":"2022-05-03T08:42:19.754248Z","shell.execute_reply.started":"2022-05-03T08:42:14.788376Z","shell.execute_reply":"2022-05-03T08:42:19.753489Z"},"trusted":true,"id":"mQ98FkJVnMAn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')\n","\n","DIR_ROOT = '/content/drive/MyDrive/Colab Notebooks/Progetto DeepLearning'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QJnCSNPknSJP","executionInfo":{"status":"ok","timestamp":1653206480045,"user_tz":-120,"elapsed":17600,"user":{"displayName":"PIETRO CALABRESE","userId":"01288920425536008567"}},"outputId":"cb62c404-a1ed-4c63-9964-aab7bb0520b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["# NON ESEGUIRE!!!!!!!!!!!!!!!!\n","#os.makedirs(DIR_ROOT+'/images')\n","#os.makedirs(DIR_ROOT+'/checkpoints')\n","#os.makedirs(DIR_ROOT+'/saved_model')"],"metadata":{"execution":{"iopub.status.busy":"2022-05-03T08:42:19.755769Z","iopub.execute_input":"2022-05-03T08:42:19.756160Z","iopub.status.idle":"2022-05-03T08:42:19.763012Z","shell.execute_reply.started":"2022-05-03T08:42:19.756124Z","shell.execute_reply":"2022-05-03T08:42:19.761880Z"},"trusted":true,"id":"bAeUSIiSnMAq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_dir = DIR_ROOT+'/checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"],"metadata":{"execution":{"iopub.status.busy":"2022-05-03T08:42:19.764243Z","iopub.execute_input":"2022-05-03T08:42:19.764481Z","iopub.status.idle":"2022-05-03T08:42:19.778754Z","shell.execute_reply.started":"2022-05-03T08:42:19.764434Z","shell.execute_reply":"2022-05-03T08:42:19.778001Z"},"trusted":true,"id":"kFou03YOnMAr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ACGAN():\n","    def __init__(self):\n","\n","        self.img_rows = 112\n","        self.img_cols = 112\n","        self.channels = 3\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","        self.num_classes = 3\n","        self.latent_dim = 1000\n","        \n","        self.optimizer = Adam(0.0002, 0.5)\n","\n","        optimizer = Adam(0.0002, 0.5)\n","        losses = ['binary_crossentropy', 'sparse_categorical_crossentropy']\n","\n","        self.discriminator = self.build_discriminator()\n","        self.discriminator.compile(loss=losses,optimizer=optimizer,metrics=['accuracy'])\n","\n","        self.generator = self.build_generator()\n","\n","        noise = Input(shape=(self.latent_dim,))\n","        label = Input(shape=(1,))\n","        img = self.generator([label,noise])\n","\n","        self.discriminator.trainable = False\n","\n","        valid, target_label = self.discriminator(img)\n","\n","        self.combined = Model([label,noise], [valid, target_label])\n","        self.combined.compile(loss=losses,optimizer=optimizer)\n","\n","    def build_generator(self):\n","\n","        noise = Input(shape=(self.latent_dim,))\n","        label = Input(shape=(1,), dtype='int32')\n","\n","        noise_branch = Dense(1024*7*7)(noise)\n","        noise_branch = relu(noise_branch)\n","        noise_branch = Reshape((7, 7, 1024))(noise_branch)\n","        noise_branch = Model(inputs=noise, outputs=noise_branch)\n","\n","        label_branch = Embedding(input_dim=50,output_dim=1)(label)\n","        label_branch = Dense(49,input_shape=(7,7))(label_branch)\n","        label_branch = linear(label_branch)\n","        label_branch = Reshape((7, 7, 1),)(label_branch)\n","        label_branch = Model(inputs=label, outputs=label_branch)\n","\n","        combined = concatenate([noise_branch.output, label_branch.output])\n","\n","        combined = Conv2DTranspose(512, (5,5), strides=(2,2),padding=\"same\")(combined)\n","        combined = BatchNormalization(momentum=0)(combined)\n","        combined = relu(combined)\n","\n","        combined = Conv2DTranspose(256, (5,5), strides=(2,2),padding=\"same\")(combined)\n","        combined = BatchNormalization(momentum=0)(combined)\n","        combined = relu(combined)\n","\n","        combined = Conv2DTranspose(128, (5,5), strides=(2,2),padding=\"same\")(combined)\n","        combined = BatchNormalization(momentum=0)(combined)\n","        combined = relu(combined)\n","\n","        combined = Conv2DTranspose(3, (5,5), strides=(2,2),padding=\"same\")(combined)\n","        combined = tanh(combined)\n","\n","\n","        model = Model(inputs=[label_branch.input, noise_branch.input], outputs=combined)\n","\n","        keras.utils.plot_model(model, DIR_ROOT+\"/generateur.png\", show_shapes=True)\n","\n","        return model\n","\n","    def build_discriminator(self):\n","\n","        model = Sequential()\n","\n","        model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), input_shape=self.img_shape, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.5))\n","\n","        model.add(Conv2D(64, kernel_size=(3,3), strides=(2,2), input_shape=self.img_shape, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.5))\n","\n","        model.add(Conv2D(128, kernel_size=(3,3), strides=(2,2), padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.5))\n","\n","        model.add(Conv2D(256, kernel_size=(3,3), strides=(2,2), padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.5))\n","\n","        model.add(Conv2D(512, kernel_size=(3,3), strides=(2,2), padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.5))\n","\n","        model.add(Flatten())\n","\n","        img = Input(shape=self.img_shape)\n","\n","        features = model(img)\n","\n","        validity = Dense(1, activation=\"sigmoid\")(features)\n","        label = Dense(self.num_classes, activation=\"softmax\")(features)\n","\n","        keras.utils.plot_model(model, DIR_ROOT+\"/discriminateur.png\", show_shapes=True)\n","\n","        return Model(img, [validity, label])\n","\n","    def train(self, epochs, batch_size=128, start=0):\n","\n","        cxr_train = keras.preprocessing.image_dataset_from_directory(DIR_ROOT+\"/datasetGAN/train\",labels=\"inferred\",batch_size=2084,image_size=(112, 112))\n","        cxr_test = keras.preprocessing.image_dataset_from_directory(DIR_ROOT+\"/datasetGAN/test\",labels=\"inferred\",batch_size=1800,image_size=(112, 112))\n","\n","        cxr_train_images = []\n","        cxr_train_labels = []\n","        cxr_test_images = []\n","        cxr_test_labels = []\n","\n","        for images, labels in cxr_train:\n","            for i in range(len(images)):\n","              cxr_train_images.append(images[i])\n","              cxr_train_labels.append(labels[i])\n","\n","        for images, labels in cxr_test:\n","            for i in range(len(images)):\n","              cxr_test_images.append(images[i])\n","              cxr_test_labels.append(labels[i])\n","\n","        cxr_train_images = np.array(cxr_train_images)\n","        cxr_train_labels = np.array(cxr_train_labels)\n","        cxr_test_images = np.array(cxr_test_images)\n","        cxr_test_labels = np.array(cxr_test_labels)\n","\n","        X_train = (cxr_train_images.astype(np.float32) - 127.5) / 127.5\n","\n","        X_test = (cxr_test_images.astype(np.float32) - 127.5) / 127.5\n","\n","        nb_train, nb_test = X_train.shape[0], X_test.shape[0]\n","\n","        train_history = defaultdict(list)\n","        test_history = defaultdict(list)\n","\n","        y_train = cxr_train_labels\n","        y_test = cxr_test_labels\n","        \n","        checkpoint = tf.train.Checkpoint(optimizer=self.optimizer,\n","                                  generator=self.generator,\n","                                  discriminator=self.discriminator,\n","                                  gan = self.combined\n","                                  )\n","\n","        ckpt_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=3)\n","\n","        if ckpt_manager.latest_checkpoint:\n","            checkpoint.restore(ckpt_manager.latest_checkpoint)\n","            print ('Latest checkpoint restored!!')\n","\n","        for epoch in range(start, epochs):\n","\n","            print('Epoch {} of {}'.format(epoch + 1, epochs))\n","            nb_batches = int(X_train.shape[0] / batch_size)\n","            progress_bar = Progbar(target=nb_batches)\n","\n","\n","            epoch_gen_loss = []\n","            epoch_disc_loss = []\n","\n","            for index in range(nb_batches):\n","                progress_bar.update(index)\n","\n","                noise = np.random.normal(0, 0.02, (batch_size, self.latent_dim))\n","\n","                image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n","                label_batch = y_train[index * batch_size:(index + 1) * batch_size]\n","\n","                sampled_labels = np.random.randint(0, 1, batch_size)\n","\n","                generated_images = self.generator.predict([sampled_labels.reshape((-1, 1)),noise], verbose=0)\n","\n","                X = np.concatenate((image_batch, generated_images))\n","                y = np.array([1] * batch_size + [0] * batch_size)\n","\n","                aux_y = np.concatenate((label_batch, sampled_labels))\n","\n","                epoch_disc_loss.append(self.discriminator.train_on_batch(X, [y, aux_y]))\n","\n","                noise = np.random.normal(0, 0.02, (2 * batch_size, self.latent_dim))\n","                sampled_labels = np.random.randint(0, 1, 2 * batch_size)\n","\n","                trick = np.ones(2 * batch_size)\n","\n","                epoch_gen_loss.append(self.combined.train_on_batch([sampled_labels.reshape((-1, 1)), noise], [trick, sampled_labels]))\n","\n","            print('\\nTesting for epoch {}:'.format(epoch + 1))\n","            noise = np.random.normal(0, 0.02, (nb_test, self.latent_dim))\n","\n","            sampled_labels = np.random.randint(0, 1, nb_test)\n","            generated_images = self.generator.predict([sampled_labels.reshape((-1, 1)), noise], verbose=False)\n","\n","            X = np.concatenate((X_test, generated_images))\n","            y = np.array([1] * nb_test + [0] * nb_test)\n","            aux_y = np.concatenate((y_test, sampled_labels), axis=0)\n","\n","            discriminator_test_loss = self.discriminator.evaluate(X, [y, aux_y], verbose=False)\n","\n","            discriminator_train_loss = np.mean(np.array(epoch_disc_loss), axis=0)\n","\n","            noise = np.random.normal(0, 0.02, (2 * nb_test, self.latent_dim))\n","            sampled_labels = np.random.randint(0, 1, 2 * nb_test)\n","\n","            trick = np.ones(2 * nb_test)\n","\n","            generator_test_loss = self.combined.evaluate([sampled_labels.reshape((-1, 1)),noise],[trick, sampled_labels], verbose=False)\n","\n","            generator_train_loss = np.mean(np.array(epoch_gen_loss), axis=0)\n","\n","            train_history['generator'].append(generator_train_loss)\n","            train_history['discriminator'].append(discriminator_train_loss)\n","\n","            test_history['generator'].append(generator_test_loss)\n","            test_history['discriminator'].append(discriminator_test_loss)\n","            \n","            ckpt_manager.save()\n","\n","            print('{0:<22s} | {1:4s} | {2:15s} | {3:5s}'.format('component', *self.discriminator.metrics_names))\n","            print('-' * 65)\n","\n","            ROW_FMT = '{0:<22s} | {1:<4.2f} | {2:<15.2f} | {3:<5.2f}'\n","            print(ROW_FMT.format('generator (train)',*train_history['generator'][-1]))\n","            print(ROW_FMT.format('generator (test)',*test_history['generator'][-1]))\n","            print(ROW_FMT.format('discriminator (train)',*train_history['discriminator'][-1]))\n","            print(ROW_FMT.format('discriminator (test)',*test_history['discriminator'][-1]))\n","\n","            \n","            self.generator.save(DIR_ROOT+'/saved_model/generator_epoch_{0:03d}.hdf5'.format(epoch))\n","\n","            r, c = 2, 2\n","            noise = np.random.normal(0, 0.02, (r * c, self.latent_dim))\n","\n","            sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n","            gen_imgs = self.generator.predict([sampled_labels, noise])\n","            gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","            fig, axs = plt.subplots(r, c)\n","            cnt = 0\n","            for i in range(r):\n","                for j in range(c):\n","                    axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n","                    axs[i,j].axis('off')\n","                    cnt += 1\n","            fig.savefig(DIR_ROOT+\"/images/%d.png\" % epoch)\n","            plt.close()\n","\n","        pickle.dump({'train': train_history, 'test': test_history},open('acgan-history.pkl', 'wb'))"],"metadata":{"execution":{"iopub.status.busy":"2022-05-03T08:42:19.782343Z","iopub.execute_input":"2022-05-03T08:42:19.782605Z","iopub.status.idle":"2022-05-03T08:42:19.836412Z","shell.execute_reply.started":"2022-05-03T08:42:19.782578Z","shell.execute_reply":"2022-05-03T08:42:19.835604Z"},"trusted":true,"id":"D8OVAaWYnMAr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acgan = ACGAN()\n","acgan.train(epochs=1500, batch_size=64, start=1480)"],"metadata":{"execution":{"iopub.status.busy":"2022-05-03T08:42:19.838102Z","iopub.execute_input":"2022-05-03T08:42:19.838592Z","iopub.status.idle":"2022-05-03T08:49:05.436412Z","shell.execute_reply.started":"2022-05-03T08:42:19.838553Z","shell.execute_reply":"2022-05-03T08:49:05.435285Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"tiUiq0gInMAw","outputId":"e035aa7a-62f2-40d7-e2ab-1b517899bd09","executionInfo":{"status":"ok","timestamp":1653211921489,"user_tz":-120,"elapsed":5440623,"user":{"displayName":"PIETRO CALABRESE","userId":"01288920425536008567"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 12125 files belonging to 3 classes.\n","Found 3030 files belonging to 3 classes.\n","Latest checkpoint restored!!\n","Epoch 1481 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1481:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 1.14 | 1.11            | 0.03 \n","generator (test)       | 0.01 | 0.00            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.01 \n","discriminator (test)   | 8.80 | 8.74            | 0.06 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1482 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1482:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 0.96 | 0.94            | 0.02 \n","generator (test)       | 0.00 | 0.00            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.01 \n","discriminator (test)   | 14.76 | 14.68           | 0.09 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1483 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1483:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 0.93 | 0.91            | 0.01 \n","generator (test)       | 0.25 | 0.25            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.01 \n","discriminator (test)   | 3.13 | 3.06            | 0.08 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1484 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1484:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 0.81 | 0.79            | 0.02 \n","generator (test)       | 0.00 | 0.00            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.01 \n","discriminator (test)   | 12.58 | 12.50           | 0.08 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1485 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1485:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 2.21 | 2.16            | 0.05 \n","generator (test)       | 0.13 | 0.13            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.01 \n","discriminator (test)   | 2.15 | 2.07            | 0.07 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1486 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1486:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 2.09 | 2.04            | 0.04 \n","generator (test)       | 0.00 | 0.00            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.01 \n","discriminator (test)   | 12.35 | 12.28           | 0.08 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1487 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1487:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 1.65 | 1.55            | 0.10 \n","generator (test)       | 10.00 | 10.00           | 0.00 \n","discriminator (train)  | 0.01 | 0.01            | 0.01 \n","discriminator (test)   | 0.17 | 0.01            | 0.16 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1488 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1488:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 1.78 | 1.75            | 0.03 \n","generator (test)       | 0.00 | 0.00            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.01 \n","discriminator (test)   | 7.84 | 7.77            | 0.07 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1489 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1489:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 0.70 | 0.67            | 0.03 \n","generator (test)       | 0.00 | 0.00            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.01 \n","discriminator (test)   | 7.73 | 7.66            | 0.07 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1490 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1490:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 0.95 | 0.93            | 0.02 \n","generator (test)       | 0.83 | 0.83            | 0.00 \n","discriminator (train)  | 0.01 | 0.01            | 0.01 \n","discriminator (test)   | 0.85 | 0.78            | 0.07 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1491 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1491:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 1.07 | 1.05            | 0.02 \n","generator (test)       | 0.02 | 0.02            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.00 \n","discriminator (test)   | 3.66 | 3.58            | 0.07 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1492 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1492:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 1.00 | 0.98            | 0.02 \n","generator (test)       | 9.77 | 9.77            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.01 \n","discriminator (test)   | 0.10 | 0.04            | 0.07 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1493 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1493:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 0.86 | 0.85            | 0.01 \n","generator (test)       | 0.01 | 0.01            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.01 \n","discriminator (test)   | 6.00 | 5.92            | 0.07 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1494 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1494:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 0.69 | 0.67            | 0.02 \n","generator (test)       | 0.00 | 0.00            | 0.00 \n","discriminator (train)  | 0.01 | 0.01            | 0.01 \n","discriminator (test)   | 9.55 | 9.46            | 0.09 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1495 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1495:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 0.89 | 0.87            | 0.02 \n","generator (test)       | 0.00 | 0.00            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.01 \n","discriminator (test)   | 15.87 | 15.81           | 0.06 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1496 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1496:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 1.29 | 1.27            | 0.02 \n","generator (test)       | 0.00 | 0.00            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.01 \n","discriminator (test)   | 8.31 | 8.24            | 0.07 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1497 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1497:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 1.40 | 1.37            | 0.03 \n","generator (test)       | 1.61 | 1.61            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.01 \n","discriminator (test)   | 0.45 | 0.37            | 0.08 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1498 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1498:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 1.08 | 1.08            | 0.01 \n","generator (test)       | 1.43 | 1.43            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.01 \n","discriminator (test)   | 0.45 | 0.37            | 0.08 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1499 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1499:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 1.34 | 1.31            | 0.02 \n","generator (test)       | 0.00 | 0.00            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.01 \n","discriminator (test)   | 22.11 | 22.05           | 0.06 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Epoch 1500 of 1500\n","188/189 [============================>.] - ETA: 0s\n","Testing for epoch 1500:\n","component              | loss | dense_loss      | dense_1_loss\n","-----------------------------------------------------------------\n","generator (train)      | 0.88 | 0.86            | 0.02 \n","generator (test)       | 0.00 | 0.00            | 0.00 \n","discriminator (train)  | 0.02 | 0.01            | 0.00 \n","discriminator (test)   | 8.00 | 7.94            | 0.07 \n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]}]}]}